{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 48.53 82.4/50.0/45.5/37.5 (BP = 0.943 ratio = 0.944 hyp_len = 17 ref_len = 18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "refs = [ # First set of references\n",
    "          ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.'],\n",
    "          # Second set of references\n",
    "          ['The dog had bit the man.', 'No one was surprised.', 'The man had bitten the dog.'],\n",
    "]\n",
    "sys = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "bleu = BLEU()\n",
    "\n",
    "bleu.corpus_score(sys, refs)\n",
    "# BLEU = 48.53 82.4/50.0/45.5/37.5 (BP = 0.943 ratio = 0.944 hyp_len = 17 ref_len = 18)\n",
    "\n",
    "# bleu.get_signature()\n",
    "# nrefs:2|case:mixed|eff:no|tok:13a|smooth:exp|version:2.0.0\n",
    "\n",
    "# chrf = CHRF()\n",
    "\n",
    "# chrf.corpus_score(sys, refs)\n",
    "# chrF2 = 59.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refs =  [[\"It's clear that my lack of humor is to blame for this awkward situation.\", 'I must have missed the memo on proper joke-telling etiquette.']]\n",
      "sys =  [\"This awkward situation seems to have stemmed from a mismatch in the group's sense of humor or a lack of clear communication about the tone of the conversation.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/qiangzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLEU = 4.79 27.6/10.7/1.9/1.0 (BP = 1.000 ratio = 1.933 hyp_len = 29 ref_len = 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# 假设json_data是包含上述数据结构的JSON字符串或从文件中读取的JSON数据\n",
    "json_data = [\n",
    "    {\n",
    "        \"Post\": \"It's clear that my lack of humor is to blame for this awkward situation. I must have missed the memo on proper joke-telling etiquette.\",\n",
    "        \"Transferred_Post\": \"This awkward situation seems to have stemmed from a mismatch in the group's sense of humor or a lack of clear communication about the tone of the conversation.\"\n",
    "    }\n",
    "    # 可以添加更多的字典元素\n",
    "]\n",
    "\n",
    "# 初始化结果列表\n",
    "refs = []\n",
    "sys = []\n",
    "\n",
    "# 遍历JSON数据\n",
    "for item in json_data:\n",
    "    # 分割Post字段中的句子\n",
    "    post_sentences = sent_tokenize(item[\"Post\"])\n",
    "    # 将分割后的句子添加到refs列表中\n",
    "    refs.append(post_sentences)\n",
    "    \n",
    "    # 将Transferred_Post字段的值添加到sys列表中\n",
    "    sys.append(item[\"Transferred_Post\"])\n",
    "\n",
    "# 打印结果\n",
    "print(\"refs = \", refs)\n",
    "print(\"sys = \", sys)\n",
    "bleu = BLEU()\n",
    "\n",
    "bleu.corpus_score(sys, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qiangzhou/Library/CloudStorage/OneDrive-UniversityofPittsburgh/projects/Digital_mental_health/BLEU/IAS2EAS.json\n",
      "所有文件处理完毕。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "# 定义原始文件夹和目标文件夹\n",
    "source_folder = '/Users/qiangzhou/Library/CloudStorage/OneDrive-UniversityofPittsburgh/projects/Digital_mental_health/BLEU'\n",
    "target_folder = '/Users/qiangzhou/Library/CloudStorage/OneDrive-UniversityofPittsburgh/projects/Digital_mental_health/BLEU'\n",
    "\n",
    "# 确保目标文件夹存在\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# 获取所有json文件的列表\n",
    "files = glob.glob(os.path.join(source_folder, '*.json'))\n",
    "\n",
    "# 初始化ID\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    # 读取文件内容\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "        for item in json_data:\n",
    "            post_sentences = sent_tokenize(item[\"Post\"])\n",
    "            transfered_post_sentences=sent_tokenize(item[\"Transferred_Post\"])\n",
    "            bleu = BLEU()\n",
    "            item[\"BLEU\"]=str(bleu.corpus_score(transfered_post_sentences, post_sentences)).split(\"=\", 1)[1].strip()\n",
    "            \n",
    "    # # 写回修改后的数据到新文件夹中\n",
    "    # # 获取原始文件名\n",
    "    base_name = os.path.basename(file)\n",
    "    new_file_name = os.path.join(target_folder, f\"BLEU4_{base_name}\")\n",
    "    with open(new_file_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "    print(file)\n",
    "\n",
    "print(\"所有文件处理完毕。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
